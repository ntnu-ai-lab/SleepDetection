{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The task is to identify sleep patterns given samples of accelerometer data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render our plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import HDFStore, DataFrame\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Loading data\n",
    "- load_pa_data gets the sensor data from the h5 file after it has been processed using the LSTM model; it converts it to a dataframe with the accelerometer data and the prediction\n",
    "- load_sleep_timings gets the start and end timings from a separate file. Those time are matched to the \"sleep profile.txt\" file that comes in PSG_analyis/sleep profile.txt\n",
    "- load_move_timing gets the amount the accelerometer data has shifted (with regards to timestamps) from the original raw psg data. It is found in a separate file called 'Move...txt'.\n",
    "- load_pa_data_match_sleep_class loads the pa_data (via load_pa_data), selects only the night for which scoring is available (using the manually set timings) and then loads shift score and the sleep scores; the pa_data is shifted according to the move score and the sleep scores are then merged to the pa_data where each row gets the closest score with a tolerance of 30sec (that's the sleep scoring frequency); in the begining there is some \"A\" labels that are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pa_data(subject_number):\n",
    "    filename = 'D:/path/ID' + subject_number + '/PSG_' + subject_number + '_timestamped_predictions.h5'\n",
    "    hf = h5py.File(filename, 'r')\n",
    "\n",
    "    data = pd.read_hdf(filename)\n",
    "    hf.close()\n",
    "    #Set the timestamp as index\n",
    "    data = data.set_index('timestamp')\n",
    "    # filter data; remove confidence for the further processing\n",
    "    data = data[['prediction','back_x' ,'back_y' ,'back_z', 'thigh_x' ,'thigh_y' ,'thigh_z']]\n",
    "    # renaming columns\n",
    "    data.columns = ['prediction','back_x' ,'back_y' ,'back_z', 'thigh_x' ,'thigh_y' ,'thigh_z']\n",
    "    return data\n",
    "\n",
    "def load_sleep_timings():\n",
    "    return pd.read_csv('D:/path/sleep_guide.csv', index_col='id')\n",
    "\n",
    "def load_move_timings():\n",
    "    return pd.read_csv('D:/path/move_guide.csv', index_col='id')\n",
    "\n",
    "\n",
    "def load_pa_data_match_sleep_class(subject_id):\n",
    "    timing = load_sleep_timings()\n",
    "    move = load_move_timings()\n",
    "\n",
    "    pa_data = load_pa_data(str(subject_id))\n",
    "    subj_night = pa_data.loc[timing.loc[subject_id].start:timing.loc[subject_id].end].copy()\n",
    "    \n",
    "    #shift data\n",
    "    shifted_data = subj_night.copy()\n",
    "    shift_x_in_sec = int(move.loc[subject_id]['shift'])\n",
    "    shifted_data = shifted_data.shift(-shift_x_in_sec * 100)\n",
    "    \n",
    "    #get sleep scores\n",
    "    sleep_profile = pd.read_csv('D:/path/ID'+str(subject_id)+'/PSG_analysis/Sleep profile.txt', header=None, sep=';', \n",
    "                                names=['timestamp','sleep_class'], skiprows=7)\n",
    "    \n",
    "    # generate timestamps from start to end with a 30s freq (30 s because we have a classification in the freq)\n",
    "    sleep_profile['timestamp'] = pd.date_range(start=timing.loc[subject_id].start, end=timing.loc[subject_id].end, freq='30s')\n",
    "\n",
    "\n",
    "    pa_sc = pd.merge_asof(shifted_data, sleep_profile, left_index=True, right_on='timestamp', tolerance=pd.Timedelta('30s'))\n",
    "    pa_sc = pa_sc[pa_sc.sleep_class != ' A']\n",
    "    pa_sc = pa_sc.set_index('timestamp')\n",
    "    pa_sc = pa_sc.dropna().copy()\n",
    "    return pa_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_scores():\n",
    "    \n",
    "    subject_ids=[1, 6 ,14, 15, 18, 19, 20, 23, 24, 25, 27, 28, 29, 30, 31, 32, 35, 37, 39]\n",
    "    \n",
    "    for id in subject_ids:\n",
    "        data = load_pa_data_match_sleep_class(id)\n",
    "        \n",
    "        filename = 'PSG' + str(id) + '_merged_data.h5'\n",
    "        data.to_hdf(filename, key = 'data')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge_scores()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
